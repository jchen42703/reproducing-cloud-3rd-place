{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Do I need to use `cv2.cvtColor(..., cv2.COLOR_BGR2RGB)`?\n",
    "* __Reason:__\n",
    "    * the 3rd place solution's code uses it:\n",
    "    ```\n",
    "    def preprocess_image(image_names, run_root=DATA_ROOT, out_root=OUTPUT_DIR, size=SIZE):\n",
    "        for i in tqdm(range(len(image_names))):\n",
    "            image_name = image_names[i]\n",
    "            path = run_root+image_name\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            H, W, C = img.shape\n",
    "            new_H = int(SIZE)\n",
    "            new_W = int(W/H*SIZE)\n",
    "            img = cv2.resize(img, (new_W, new_H))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(OUTPUT_DIR + image_name, img)\n",
    "    ```\n",
    "    * Mine looks like this:\n",
    "    ```\n",
    "    def convert_images(filename, arch_out, file_type, out_shape=(640, 320)):\n",
    "    \"\"\"\n",
    "    Reads an image and converts it to a desired file format\n",
    "    \"\"\"\n",
    "    img = np.array(cv2.imread(filename))\n",
    "\n",
    "    img = cv2.resize(img, out_shape)\n",
    "    output = cv2.imencode(file_type, img)[1]\n",
    "    name = f\"{Path(filename).stem}{file_type}\"\n",
    "    arch_out.writestr(name, output)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The experiment here is to test the tangible differences between my pipeline and the 3rd place one. Both are:\n",
    "* resized to (384, 576) ((576, 384) for cv2)\n",
    "* saved as .jpg files in `dset_dir/output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "dset_dir = r\"C:\\Users\\jchen\\Desktop\\Datasets\\Understanding Clouds\"\n",
    "ex_img_fname = \"test_image.jpg\"\n",
    "\n",
    "def preprocess_3rd_place(img_name, in_dir, out_dir, resize_size=(576, 384)):\n",
    "    img = cv2.imread(os.path.join(in_dir, img_name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, resize_size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    return img\n",
    "    \n",
    "def preprocess_mine(img_name, in_dir, out_dir, resize_size=(576, 384)):\n",
    "    img = cv2.imread(os.path.join(in_dir, img_name))\n",
    "    img = cv2.resize(img, resize_size)\n",
    "    return img\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"img_name\": ex_img_fname,\n",
    "    \"in_dir\": dset_dir,\n",
    "    \"out_dir\": os.path.join(dset_dir, \"output\"),\n",
    "    \"resize_size\": (576, 384),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 576, 3), (384, 576, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img_3rd = np.array(preprocess_3rd_place(**fn_kwargs))\n",
    "img_mine = np.array(preprocess_mine(**fn_kwargs))\n",
    "img_3rd.shape, img_mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(img_3rd, img_mine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is no difference. Maybe resolution is a reason for the difference in performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Mask Creation (3rd Place v. Mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "root_dset_dir = r\"C:\\Users\\Joseph\\kaggle_challenges\\Understanding Clouds\"\n",
    "partial_dset, train_csv_path = join(root_dset_dir, \"partial_dataset\"), join(root_dset_dir, \"train.csv\")\n",
    "sample_sub_path = join(root_dset_dir, \"sample_submission.csv\")\n",
    "# importing clouds locally\n",
    "repos_path = r\"C:\\Users\\Joseph\\kaggle_challenges\\reproducing-cloud-3rd-place\"\n",
    "os.chdir(repos_path)\n",
    "import clouds\n",
    "os.chdir(r\"C:\\Users\\Joseph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 training images\n",
      "2 test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5546/5546 [12:14<00:00,  6.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from clouds.preprocess import Preprocessor\n",
    "from clouds.experiments import setup_train_and_sub_df\n",
    "\n",
    "size_str = \"576_384\"\n",
    "config = {\n",
    "    \"paths_params\": {\n",
    "        \"train_csv_path\": train_csv_path,\n",
    "        \"sample_sub_csv_path\": sample_sub_path,\n",
    "        \"train_dir\": join(partial_dset, \"train_images\"),\n",
    "        \"test_dir\": join(partial_dset, \"test_images\"),\n",
    "        \"train_out\": join(partial_dset, f\"train{size_str}.zip\"),\n",
    "        \"test_out\": join(partial_dset, f\"test{size_str}.zip\"),\n",
    "        \"mask_out\": join(partial_dset, f\"mask{size_str}.zip\"),\n",
    "    },\n",
    "    \"file_type\": \".jpg\",\n",
    "    \"out_shape_cv2\": (576, 384),\n",
    "}\n",
    "\n",
    "def main(config):\n",
    "    paths_params = config[\"paths_params\"]\n",
    "    paths_dict = {\n",
    "        \"train_dir\": paths_params[\"train_dir\"],\n",
    "        \"test_dir\": paths_params[\"test_dir\"],\n",
    "        \"train_out\": paths_params[\"train_out\"],\n",
    "        \"test_out\": paths_params[\"test_out\"],\n",
    "        \"mask_out\": paths_params[\"mask_out\"],\n",
    "    }\n",
    "    train, sub, _ = setup_train_and_sub_df(paths_params[\"train_csv_path\"],\n",
    "                                           paths_params[\"sample_sub_csv_path\"])\n",
    "    preprocessor = Preprocessor(train, paths_dict, tuple(config[\"out_shape_cv2\"]),\n",
    "                                config[\"file_type\"])\n",
    "    preprocessor.execute_masks()\n",
    "    \n",
    "main(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(train_csv_path)\n",
    "df[\"im_id\"] = df[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 2 training images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 22184/22184 [13:52<00:00, 26.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3rd place solution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "SIZE = 384\n",
    "\n",
    "df_train = pd.read_csv(config[\"paths_params\"][\"train_csv_path\"])\n",
    "df_test = pd.read_csv(config[\"paths_params\"][\"sample_sub_csv_path\"])\n",
    "DATA_ROOT = config[\"paths_params\"][\"train_dir\"]\n",
    "OUTPUT_DIR = join(partial_dset, \"train576_384_3rd_place\")\n",
    "\n",
    "image_names = os.listdir(DATA_ROOT)\n",
    "# image_names = df_train['Image_Label'].apply(lambda x: x.split('_')[0]).unique().tolist()\n",
    "# image_names += df_test['Image_Label'].apply(lambda x: x.split('_')[0]).unique().tolist()\n",
    "\n",
    "print(f\"Preprocessing {len(image_names)} training images.\")\n",
    "\n",
    "def preprocess_masks(image_names, df, run_root=DATA_ROOT, out_root=OUTPUT_DIR, size=SIZE):\n",
    "    \"\"\"\n",
    "    Converts rles to masks and saves them as numpy arrays as `image_name` in `image_names`\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def resize_mask(df, size=SIZE):\n",
    "    H = size\n",
    "    W = int(3/2*H)\n",
    "    df.fillna('', inplace=True)\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        rle = df['EncodedPixels'].values[i]\n",
    "        if rle != '':\n",
    "            mask = rle2mask(rle, height=1400, width=2100, fill_value=1)\n",
    "            mask = (cv2.resize(mask, (W, H)) > 0).astype(int)\n",
    "            new_rle = mask2rle(mask)\n",
    "        else:\n",
    "            new_rle = rle\n",
    "        df['EncodedPixels'].iloc[i] = new_rle\n",
    "    df.to_csv(join(DATA_ROOT, f'train_{SIZE}.csv'), index=None)\n",
    "\n",
    "def mask2rle(mask):  # 1:53\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = mask.T.flatten()\n",
    "    if pixels.sum() == 0:\n",
    "        rle = ''\n",
    "    else:\n",
    "        pixels = np.concatenate([[0], pixels, [0]])\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "        runs[1::2] -= runs[::2]\n",
    "        rle = ' '.join(str(x) for x in runs)\n",
    "    return rle\n",
    "\n",
    "def rle2mask(rle, height=256, width=1600, fill_value=1):\n",
    "    mask = np.zeros((height, width), np.float32)\n",
    "    if rle != '':\n",
    "        mask = mask.reshape(-1)\n",
    "        r = [int(r) for r in rle.split(' ')]\n",
    "        r = np.array(r).reshape(-1, 2)\n",
    "        for start, length in r:\n",
    "            start = start - 1  # ???? 0 or 1 index ???\n",
    "            mask[start:(start + length)] = fill_value\n",
    "        mask = mask.reshape(width, height).T\n",
    "    return mask\n",
    "\n",
    "resize_mask(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_3rd_place(df, image_name, shape):\n",
    "    item = df_3rd.loc[df_3rd[\"Image_Label\"] == image_name]\n",
    "    index = item.index[0]\n",
    "    h, w = shape[0], shape[1]\n",
    "    mask = np.zeros((h, w, 4), dtype=np.float32)\n",
    "    labels = item[\"Labels\"][index]#.to_string(index=False)[1:]\n",
    "    if len(labels) == 1:\n",
    "        label = int(labels)\n",
    "        rle = item['EncodedPixels'][index]\n",
    "        mask[:, :, label] =  rle2mask(rle, h, w)\n",
    "    else:\n",
    "        labels = [int(x) for x in labels.split(' ')]\n",
    "        rles = item['EncodedPixels'][index].split('|')\n",
    "        for label, rle in zip(labels, rles):\n",
    "            mask[:, :, label] = rle2mask(rle, h, w)\n",
    "    return mask\n",
    "\n",
    "def make_mask_resized_dset(df: pd.DataFrame, image_name: str=\"img.jpg\",\n",
    "                           masks_dir: str=\"./masks\",\n",
    "                           shape: tuple=(320, 640)):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \"\"\"\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "    df = df[df[\"im_id\"] == image_name]\n",
    "    for idx, im_name in enumerate(df[\"im_id\"].values):\n",
    "        for classidx, classid in enumerate([\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]):\n",
    "            mask = cv2.imread(os.path.join(masks_dir, f\"{classid}{im_name}\"),\n",
    "                              cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                continue\n",
    "            # if mask[:,:,0].shape != (350,525):\n",
    "            #     mask = cv2.resize(mask, (525,350))\n",
    "            masks[:, :, classidx] = mask\n",
    "    masks = masks/255\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name: 00a0954.jpg\n",
      "5546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Is_defect</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>00a0954.jpg</td>\n",
       "      <td>2 3</td>\n",
       "      <td>1</td>\n",
       "      <td>62221 92 62605 92 62989 92 63373 92 63757 92 6...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>00b81e1.jpg</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>1</td>\n",
       "      <td>121224 99 121608 99 121992 99 122376 99 122760...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_Label Labels  Is_defect  \\\n",
       "13  00a0954.jpg    2 3          1   \n",
       "14  00b81e1.jpg  1 2 3          1   \n",
       "\n",
       "                                        EncodedPixels  fold  \n",
       "13  62221 92 62605 92 62989 92 63373 92 63757 92 6...     2  \n",
       "14  121224 99 121608 99 121992 99 122376 99 122760...     1  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the images and seeing if they are the same\n",
    "## EXAMPLE 1\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mine_mask_dir = join(partial_dset, f\"mask{size_str}\")\n",
    "img_name = image_names[0]\n",
    "print(f\"Image name: {img_name}\")\n",
    "\n",
    "df_train = pd.read_csv(config[\"paths_params\"][\"train_csv_path\"])\n",
    "# 3rd place dfs\n",
    "file_dir = r\"C:\\Users\\Joseph\\Downloaded_Code\\kaggle-cloud-organization-master\\kaggle-cloud-organization-master\\files\"\n",
    "fivefold = pd.read_csv(join(file_dir, \"5-folds_384.csv\"))\n",
    "# fivefold[\"Labels\"] = fivefold[\"Labels\"].apply(str)\n",
    "print(len(fivefold))\n",
    "\n",
    "df_list = []\n",
    "for img_name in image_names:\n",
    "    df_list.append(fivefold.loc[fivefold[\"Image_Label\"] == img_name])\n",
    "df_3rd = pd.concat(df_list)\n",
    "df_3rd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 576, 4), (384, 576, 4))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"im_id\"] = df_train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "mine_mask = make_mask_resized_dset(df_train, img_name, mine_mask_dir, shape=(384, 576))\n",
    "mask_3rd = create_mask_3rd_place(df_3rd, img_name, shape=(384, 576))\n",
    "\n",
    "mine_mask.shape, mask_3rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.        , 0.00392157, 0.00784314, 0.01176471, 0.01568628,\n",
       "         0.01960784, 0.02352941, 0.02745098, 0.972549  , 0.9764706 ,\n",
       "         0.98039216, 0.9843137 , 0.9882353 , 0.99215686, 0.99607843,\n",
       "         1.        ], dtype=float32),\n",
       "  array([653587,   1294,    450,    228,     95,     30,      4,      3,\n",
       "              1,      6,     27,     76,    177,    379,   1601, 226778],\n",
       "        dtype=int64)),\n",
       " (array([0., 1.], dtype=float32), array([654631, 230105], dtype=int64)))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mine_mask, return_counts=True), np.unique(mask_3rd, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([655691, 229045], dtype=int64)),\n",
       " (array([0., 1.], dtype=float32), array([654631, 230105], dtype=int64)))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique((mine_mask > 0.9).astype(int), return_counts=True), np.unique(mask_3rd, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Question: If I write a binary array to a jpg and load it (+ threshold), will it yield the same array?\n",
    "* With jpg? `No.`\n",
    "* With png? `Yes.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Distribution: (array([0, 1], dtype=int32), array([110457, 110727], dtype=int64))\n",
      "After reading the array: (array([0, 1]), array([110831, 110353], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fname = \"example_temp.jpg\"\n",
    "array = np.random.choice([0, 1], size=(1400, 2100))\n",
    "array_resized = cv2.resize(array, (576, 384), \n",
    "                           interpolation=cv2.INTER_NEAREST)\n",
    "print(f\"Original Distribution: {np.unique(array_resized, return_counts=True)}\")\n",
    "cv2.imwrite(fname, array_resized)\n",
    "\n",
    "read_array = (np.array(cv2.imread(fname, cv2.IMREAD_GRAYSCALE)) > 0.05).astype(int)\n",
    "print(f\"After reading the array: {np.unique(read_array, return_counts=True)}\")\n",
    "os.remove(fname)\n",
    "np.array_equal(array_resized, read_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Comparing 3rd Place Pipeline with Mine (Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "root_dset_dir = r\"C:\\Users\\Joseph\\kaggle_challenges\\Understanding Clouds\"\n",
    "partial_dset, train_csv_path = join(root_dset_dir, \"partial_dataset\"), join(root_dset_dir, \"train.csv\")\n",
    "sample_sub_path = join(root_dset_dir, \"sample_submission.csv\")\n",
    "# importing clouds locally\n",
    "repos_path = r\"C:\\Users\\Joseph\\kaggle_challenges\\reproducing-cloud-3rd-place\"\n",
    "os.chdir(repos_path)\n",
    "import clouds\n",
    "os.chdir(r\"C:\\Users\\Joseph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 training images\n",
      "2 test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00,  3.71it/s]\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 10.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from clouds.preprocess import Preprocessor\n",
    "from clouds.experiments import setup_train_and_sub_df\n",
    "\n",
    "size_str = \"576_384\"\n",
    "config = {\n",
    "    \"paths_params\": {\n",
    "        \"train_csv_path\": train_csv_path,\n",
    "        \"sample_sub_csv_path\": sample_sub_path,\n",
    "        \"train_dir\": join(partial_dset, \"train_images\"),\n",
    "        \"test_dir\": join(partial_dset, \"test_images\"),\n",
    "        \"train_out\": join(partial_dset, f\"train{size_str}.zip\"),\n",
    "        \"test_out\": join(partial_dset, f\"test{size_str}.zip\"),\n",
    "        \"mask_out\": join(partial_dset, f\"mask{size_str}.zip\"),\n",
    "    },\n",
    "    \"file_type\": \".jpg\",\n",
    "    \"out_shape_cv2\": (576, 384),\n",
    "}\n",
    "\n",
    "def main(config):\n",
    "    paths_params = config[\"paths_params\"]\n",
    "    paths_dict = {\n",
    "        \"train_dir\": paths_params[\"train_dir\"],\n",
    "        \"test_dir\": paths_params[\"test_dir\"],\n",
    "        \"train_out\": paths_params[\"train_out\"],\n",
    "        \"test_out\": paths_params[\"test_out\"],\n",
    "        \"mask_out\": paths_params[\"mask_out\"],\n",
    "    }\n",
    "    train, sub, _ = setup_train_and_sub_df(paths_params[\"train_csv_path\"],\n",
    "                                           paths_params[\"sample_sub_csv_path\"])\n",
    "    preprocessor = Preprocessor(train, paths_dict, tuple(config[\"out_shape_cv2\"]),\n",
    "                                config[\"file_type\"])\n",
    "    preprocessor.execute_train_test()\n",
    "    \n",
    "main(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 2 training images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 10.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3rd place solution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "SIZE = 384\n",
    "\n",
    "df_train = pd.read_csv(config[\"paths_params\"][\"train_csv_path\"])\n",
    "df_test = pd.read_csv(config[\"paths_params\"][\"sample_sub_csv_path\"])\n",
    "DATA_ROOT = config[\"paths_params\"][\"train_dir\"]\n",
    "OUTPUT_DIR = join(partial_dset, \"train576_384_3rd_place\")\n",
    "\n",
    "image_names = os.listdir(DATA_ROOT)\n",
    "# image_names = df_train['Image_Label'].apply(lambda x: x.split('_')[0]).unique().tolist()\n",
    "# image_names += df_test['Image_Label'].apply(lambda x: x.split('_')[0]).unique().tolist()\n",
    "\n",
    "print(f\"Preprocessing {len(image_names)} training images.\")\n",
    "\n",
    "def preprocess_image(image_names, run_root=DATA_ROOT, out_root=OUTPUT_DIR, size=SIZE):\n",
    "    for i in tqdm(range(len(image_names))):\n",
    "        image_name = image_names[i]\n",
    "        img = cv2.imread(join(run_root, image_name))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        H, W, C = img.shape\n",
    "        new_H = int(SIZE)\n",
    "        new_W = int(W/H*SIZE)\n",
    "        img = cv2.resize(img, (new_W, new_H))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        out_path = join(out_root, image_name)\n",
    "        cv2.imwrite(out_path, img)\n",
    "\n",
    "preprocess_image(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name: 00a0954.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((384, 576, 3), (384, 576, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the images and seeing if they are the same\n",
    "## EXAMPLE 1\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_name = image_names[0]\n",
    "print(f\"Image name: {img_name}\")\n",
    "mine_img = np.array(cv2.imread(join(partial_dset, \"train576_384\", img_name)))\n",
    "img_3rd = np.array(cv2.imread(join(partial_dset, \"train576_384_3rd_place\", img_name)))\n",
    "\n",
    "mine_img.shape, img_3rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(mine_img, img_3rd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
